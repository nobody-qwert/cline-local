syntax = "proto3";

package cline;
import "cline/common.proto";
option java_package = "bot.cline.proto";
option java_multiple_files = true;

// Service for model-related operations
service ModelsService {
  // Fetches available models from Ollama
  rpc getOllamaModels(StringRequest) returns (StringArray);
  // Fetches available models from LM Studio
  rpc getLmStudioModels(StringRequest) returns (StringArray);
  // Updates API configuration
  rpc updateApiConfigurationProto(UpdateApiConfigurationRequest) returns (Empty);
}



// Price tier for tiered pricing models
message PriceTier {
  int32 token_limit = 1;  // Upper limit (inclusive) of input tokens for this price
  double price = 2;       // Price per million tokens for this tier
}

// Thinking configuration for models that support thinking/reasoning
message ThinkingConfig {
  optional int32 max_budget = 1;                    // Max allowed thinking budget tokens
  optional double output_price = 2;                 // Output price per million tokens when budget > 0
  repeated PriceTier output_price_tiers = 3;        // Optional: Tiered output price when budget > 0
}

// Model tier for tiered pricing structures
message ModelTier {
  int32 context_window = 1;
  optional double input_price = 2;
  optional double output_price = 3;
  optional double cache_writes_price = 4;
  optional double cache_reads_price = 5;
}

// For OpenRouterCompatibleModelInfo structure in OpenRouterModels
message OpenRouterModelInfo {
  optional int32 max_tokens = 1;
  optional int32 context_window = 2;
  optional bool supports_images = 3;
  bool supports_prompt_cache = 4;
  optional double input_price = 5;
  optional double output_price = 6;
  optional double cache_writes_price = 7;
  optional double cache_reads_price = 8;
  optional string description = 9;
  optional ThinkingConfig thinking_config = 10;
  optional bool supports_global_endpoint = 11;
  repeated ModelTier tiers = 12;
}

// Shared response message for model information
message OpenRouterCompatibleModelInfo {
  map<string, OpenRouterModelInfo> models = 1;
}


// Request for updating API configuration
message UpdateApiConfigurationRequest {
  Metadata metadata = 1;
  ModelsApiConfiguration api_configuration = 2;
}

enum ApiProvider {
  OLLAMA = 0;
  LMSTUDIO = 1;
}

// Model info for OpenAI-compatible models
message OpenAiCompatibleModelInfo {
  optional int32 max_tokens = 1;
  optional int32 context_window = 2;
  optional bool supports_images = 3;
  bool supports_prompt_cache = 4;
  optional double input_price = 5;
  optional double output_price = 6;
  optional ThinkingConfig thinking_config = 7;
  optional bool supports_global_endpoint = 8;
  optional double cache_writes_price = 9;
  optional double cache_reads_price = 10;
  optional string description = 11;
  repeated ModelTier tiers = 12;
  optional double temperature = 13;
  optional bool is_r1_format_required = 14;
}

// Model info for LiteLLM models
message LiteLLMModelInfo {
  optional int32 max_tokens = 1;
  optional int32 context_window = 2;
  optional bool supports_images = 3;
  bool supports_prompt_cache = 4;
  optional double input_price = 5;
  optional double output_price = 6;
  optional ThinkingConfig thinking_config = 7;
  optional bool supports_global_endpoint = 8;
  optional double cache_writes_price = 9;
  optional double cache_reads_price = 10;
  optional string description = 11;
  repeated ModelTier tiers = 12;
  optional double temperature = 13;
}

// Main ApiConfiguration message
message ModelsApiConfiguration {
  // Global configuration fields (local-only)
  optional string ulid = 1;
  optional string ollama_base_url = 2;
  optional string ollama_api_key = 3;
  optional string lm_studio_base_url = 4;
  optional int32 request_timeout_ms = 5;
  optional string lm_studio_max_tokens = 6;

  // Plan mode configurations (local-only)
  optional ApiProvider plan_mode_api_provider = 100;
  optional string plan_mode_api_model_id = 101;
  optional int32 plan_mode_thinking_budget_tokens = 102;
  optional string plan_mode_ollama_model_id = 111;
  optional string plan_mode_lm_studio_model_id = 112;

  // Act mode configurations (local-only)
  optional ApiProvider act_mode_api_provider = 200;
  optional string act_mode_api_model_id = 201;
  optional int32 act_mode_thinking_budget_tokens = 202;
  optional string act_mode_ollama_model_id = 211;
  optional string act_mode_lm_studio_model_id = 212;

  // Favorites
  repeated string favorited_model_ids = 300;
}
